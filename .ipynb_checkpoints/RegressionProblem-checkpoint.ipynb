{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of analysis is used when you have continuous target variable. You have target variable so it's supervised. For example can be used to:\n",
    "- Understand relationship between variables\n",
    "- Forecast: predicting the sales in the future.\n",
    "- Evaluating trends\n",
    "\n",
    "Here we will talk about:\n",
    "- implementation of linear regression\n",
    "- outlier\n",
    "- model evaluation and common problem\n",
    "- how about non linear?\n",
    "\n",
    "Categories:\n",
    "- simple linear regression\n",
    "- multiple linear regression\n",
    "\n",
    "We learn the weight / gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "What is the cost function of this problem?\n",
    "\n",
    "$$J(w)=\\frac{1}{2}\\sum_{i=1}^{n}\\left( y^{(i)}-\\hat{y}^{(i)} \\right)^2$$\n",
    "\n",
    "where $\\hat{y}^{(i)}$ is predicted value of point $i$. Using above cost function ($J(\\pmb w)$), the gradient of that cost function with respect to weight ($w$) would be partial derivative as follows\n",
    "\n",
    "$$\\frac{\\delta J}{\\delta w_j}=-\\sum_i \\left( y^{(i)} - \\hat{y}^{(i)}) \\right)x_j^{(i)} $$\n",
    "\n",
    "so the weight should be updated with\n",
    "\n",
    "$$\\Delta w_j=-\\eta\\frac{\\delta J}{\\delta w_j}=\\eta \\sum_i \\left( y^{(i)} - \\hat{y}^{(i)}) \\right)x_j^{(i)} $$\n",
    "\n",
    "So it really is the same as Adaline, but without unit step function. So we can also use gradient descent, or stochastic gradient descent. I forget again how to do gradient descet dudeeeee....\n",
    "\n",
    "gradient descent steps:\n",
    "- calculate $\\Delta \\pmb{w}$\n",
    "- update weight $\\pmb{w}:=\\pmb{w}+\\Delta \\pmb{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent implementation:\n",
    "It's just the same as Adaline without step function at the `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegressionGD(object):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
